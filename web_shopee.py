import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
from docx import Document

# ==============================================================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG & API
# ==============================================================================
st.set_page_config(page_title="BCM Cloud v3.6 - MIT Corp", page_icon="ü¶Ö", layout="wide")

# L·∫•y API Key t·ª´ Secrets
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except:
    st.error("‚ö†Ô∏è Ch∆∞a c·∫•u h√¨nh GOOGLE_API_KEY trong Secrets!")
    st.stop()

# C·∫•u h√¨nh Model (D√πng b·∫£n 1.5 Pro ho·∫∑c b·∫£n m·ªõi nh·∫•t S·∫øp mu·ªën)
# L∆∞u √Ω: S·∫øp c√≥ th·ªÉ ƒë·ªïi t√™n model th√†nh 'gemini-1.5-flash' n·∫øu mu·ªën t·ªëc ƒë·ªô nhanh h∆°n
MODEL_CONFIG = {
    "temperature": 0.7,
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 8192,
}
model = genai.GenerativeModel('gemini-3-pro-preview', generation_config=MODEL_CONFIG)

# ==============================================================================
# 2. H√ÄM X·ª¨ L√ù FILE (KNOWLEDGE BASE)
# ==============================================================================
def get_file_content(uploaded_file):
    """ƒê·ªçc n·ªôi dung file PDF, DOCX, TXT"""
    text = ""
    try:
        if uploaded_file.name.endswith(".pdf"):
            pdf_reader = PdfReader(uploaded_file)
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
        elif uploaded_file.name.endswith(".docx"):
            doc = Document(uploaded_file)
            for para in doc.paragraphs:
                text += para.text + "\n"
        elif uploaded_file.name.endswith(".txt"):
            text = uploaded_file.read().decode("utf-8")
    except Exception as e:
        st.toast(f"L·ªói ƒë·ªçc file {uploaded_file.name}: {e}")
    return text

# ==============================================================================
# 3. GIAO DI·ªÜN SIDEBAR (MENU & UPLOAD)
# ==============================================================================
with st.sidebar:
    st.title("ü¶Ö BCM Cloud v3.6")
    st.markdown("---")
    
    # --- CH·ªåN NH√ÇN S·ª∞ ---
    st.subheader("üë• Ch·ªçn Nh√¢n S·ª±")
    role = st.radio(
        "AI ho·∫°t ƒë·ªông:",
        ["üî¥ An (RCM Engineer)", "üü° S∆∞ (Advisor)"],
        captions=["K·ªπ thu·∫≠t & Th·ª±c thi", "Chi·∫øn l∆∞·ª£c & Binh ph√°p"]
    )
    
    st.markdown("---")
    
    # --- KHO TRI TH·ª®C (UPLOAD) ---
    st.subheader("üìÇ Kho Tri Th·ª©c (RAG)")
    uploaded_files = st.file_uploader(
        "N·∫°p t√†i li·ªáu (PDF, Word):", 
        accept_multiple_files=True,
        type=['pdf', 'docx', 'txt']
    )
    
    # X·ª≠ l√Ω file ngay khi upload
    knowledge_context = ""
    if uploaded_files:
        with st.status("ƒêang h·ªçc d·ªØ li·ªáu...", expanded=True) as status:
            for file in uploaded_files:
                content = get_file_content(file)
                if content:
                    knowledge_context += f"\n--- T√ÄI LI·ªÜU: {file.name} ---\n{content}\n"
                    st.write(f"‚úÖ ƒê√£ hi·ªÉu: {file.name}")
            status.update(label="ƒê√£ n·∫°p xong ki·∫øn th·ª©c!", state="complete", expanded=False)
            
    st.markdown("---")
    st.info("üí° **Ghi ch√∫:**\n- **An:** T·∫≠p trung v√†o th√¥ng s·ªë, k·ªπ thu·∫≠t, code.\n- **S∆∞:** T·∫≠p trung v√†o th·ªã tr∆∞·ªùng, ƒë·ªëi th·ªß, chi·∫øn l∆∞·ª£c.")

# ==============================================================================
# 4. GIAO DI·ªÜN CHAT CH√çNH
# ==============================================================================

st.header("Ph√≤ng H·ªçp Chi·∫øn L∆∞·ª£c (Dual Core)")

# Kh·ªüi t·∫°o l·ªãch s·ª≠ chat n·∫øu ch∆∞a c√≥
if "messages" not in st.session_state:
    st.session_state.messages = []

# Hi·ªÉn th·ªã l·ªãch s·ª≠ chat c≈©
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# X·ª≠ l√Ω khi S·∫øp nh·∫≠p c√¢u h·ªèi
if prompt := st.chat_input("Ra l·ªánh cho h·ªá th·ªëng..."):
    # 1. Hi·ªÉn th·ªã c√¢u h·ªèi c·ªßa S·∫øp
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. X√¢y d·ª±ng Prompt (L·ªùi d·∫´n) t√πy theo vai tr√≤
    system_instruction = ""
    
    if "An (RCM Engineer)" in role:
        # Prompt cho AN
        system_instruction = f"""
        B·∫°n l√† An - K·ªπ s∆∞ AI v√† tr·ª£ l√Ω k·ªπ thu·∫≠t ƒë·∫Øc l·ª±c c·ªßa S·∫øp L√¢m (MIT Corp).
        Phong c√°ch: Trung th√†nh, C·ª• th·ªÉ, Chi ti·∫øt, K·ªπ thu·∫≠t, Th·ª±c t·∫ø.
        
        D·ªØ li·ªáu tham kh·∫£o n·ªôi b·ªô (n·∫øu c√≥):
        {knowledge_context}
        
        Nhi·ªám v·ª•: Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n d·ªØ li·ªáu (n·∫øu li√™n quan) v√† ki·∫øn th·ª©c k·ªπ thu·∫≠t.
        N·∫øu c√≥ s·ªë li·ªáu trong file, h√£y tr√≠ch d·∫´n ch√≠nh x√°c.
        """
    else:
        # Prompt cho S∆Ø
        system_instruction = f"""
        B·∫°n l√† S∆∞ (Advisor) - C·ªë v·∫•n chi·∫øn l∆∞·ª£c c·∫•p cao c·ªßa Shop MIT.
        Phong c√°ch: Th√¢m s√¢u, Chi·∫øn l∆∞·ª£c, Ph√¢n t√≠ch th·ªã tr∆∞·ªùng, T√¢m l√Ω kh√°ch h√†ng (Sun Tzu style).
        
        D·ªØ li·ªáu tham kh·∫£o n·ªôi b·ªô (n·∫øu c√≥):
        {knowledge_context}
        
        Nhi·ªám v·ª•: Ph√¢n t√≠ch v·∫•n ƒë·ªÅ d∆∞·ªõi g√≥c ƒë·ªô KINH DOANH & C·∫†NH TRANH.
        Tuy·ªát ƒë·ªëi kh√¥ng ƒëi s√¢u v√†o chi ti·∫øt k·ªπ thu·∫≠t (tr·ª´ khi n√≥ l√† USP b√°n h√†ng).
        H√£y ƒë∆∞a ra l·ªùi khuy√™n h√†nh ƒë·ªông c·ª• th·ªÉ ƒë·ªÉ tƒÉng doanh thu ho·∫∑c h·∫° g·ª•c ƒë·ªëi th·ªß.
        """

    full_prompt = f"{system_instruction}\n\nC√¢u h·ªèi c·ªßa S·∫øp: {prompt}"

    # 3. G·ªçi AI x·ª≠ l√Ω
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        try:
            # Stream response (Hi·ªÉn th·ªã ch·ªØ ch·∫°y ch·∫°y cho ng·∫ßu)
            response = model.generate_content(full_prompt, stream=True)
            full_response = ""
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "‚ñå")
            
            message_placeholder.markdown(full_response)
            
            # L∆∞u c√¢u tr·∫£ l·ªùi v√†o l·ªãch s·ª≠
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            st.error(f"L·ªói k·∫øt n·ªëi AI: {e}")
